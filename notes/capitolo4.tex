\chapter{Classificazione}

\section{Introduzione alla classificazione}
La classificazione è un altro dei problemi tipici che può essere risolto tramite un algoritmo di Machine Learning. Riguarda lo stabilire se un dato input appartiene ad una tra delle classi prestabilite dal problema. Il target non sarà più un valore $\mathbb{R}$, ma una tra $k$ classi.
Per studiare la classificazione, andremo a stabilire i requisiti e i nostri obiettivi.
\begin{itemize}
	\item Un modello ben definito.
	\item Una funzione di loss per stabilire lo scarto con i risultati attesi.
	\item Un algoritmo di learning per trovare i parametri.
	\item Delle misure di valutazione.
	\item Niente overfitting!
\end{itemize}

\subsection{Classificazione: binaria e di classe}
Identifichiamo due tipi di task di classificazione:
\begin{itemize}
	\item \textbf{Classificazione binaria.}\\
	Le etichette $y \in \{ 0,1\}$. Va associata ad $x$ una delle due etichette, o le probabilità relativa a ciascuna delle due.
	\item \textbf{Classificazione di classe.}\\
	Le etichette $y \in \{ 0,1, \dots, k-1\}$. Va associata ad $x$ una delle etichette, o la probabilità relativa a ciascuna di esse.
\end{itemize}

È fondamentale sottolineare l'importanza che gli output di questi algoritmi siano sempre $\in[0,1]$, in quanto da interpretare come \textbf{probabilità}.
\section{Classificazione binaria}
Nonostante i classificatori binari possano sembrare limitati, questi trovano applicazioni in vari task: solitamente, questi si basano sulla suddivisione di immagini più grandi in \textit{patches} più piccole, con una successiva, appunto, classificazione, per individuare determinati elementi. Nel medical imaging, i classificatori binari possono individuare piccoli tumori. Nei controlli qualità in ambito industriale, possono individuare imperfezioni nei materiali. Nel campo più generale della computer vision, gli algoritmi di classificazione (binaria e non) sono fondamentali. 

\subsection{Perché non usare la regressione lineare per la classificazione?}

Si potrebbe pensare di usare un modello di regressione lineare per effettuare classificazione binaria, e l'intuizione non sarebbe nemmeno totalmente sbagliata: potremmo usare, ad esempio, la regressione per trovare una retta che unisce i dati in maniera opportuna, e in funzione della pendenza di questa retta, stabilire un valore di sogliatura per distinguere due classi.

Forniamo il seguente esempio: vogliamo addestrare un modello per prevedere se un tumore è benigno o maligno usando una singola feature (dimensione del tumore).

Usiamo la regressione lineare e facciamo il fitting di una retta nello spazio (troviamo la retta, cioè la funzione che meglio si posiziona a media tra tutti i punti). Possiamo trovare il miglior $y = \vartheta^Tx$ dal nostro set di dati e quindi selezionare una soglia su y per classificare quando il tumore è maligno o meno.

\begin{figure}[tbph]
	\centering
	\includegraphics[width=0.7\linewidth]{images/regression-for-classification.png}
\end{figure}

$$
h_\vartheta(x) \leq 0.5 \to 0 \qquad h_\vartheta(x) \geq 0.5 \to 1
$$

Ci sono due criticità. La prima, riguarda la versatilità del modello: il fitting della retta non è opportuno, in  quanto la regressione lineare dipende fortemente dalla distribuzione dei dati.\\

\begin{figure}[tbph]
	\centering
	\includegraphics[width=0.7\linewidth]{images/regression-for-classification2}
\end{figure}

La seconda criticità riguarda invece la $y$, non sempre limitata tra 0 e 1, come ci aspettiamo in un modello di classificazione binaria. Come ci comportiamo con valori più grandi di 1? E con valori minori di 0? 

\section{Regressione logicistica - Sigmoide}
Se la regressione lineare restituisce una $y$ non limitata tra 0 e 1, la \textbf{regressione logistica} risolve il problema con una funzione, detta \textbf{sigmoide}, applicata sul risultato $z = \vartheta^T$ del modello di regressione. La \textbf{sigmoide} una funzione del tipo

$$
\overline{\sigma}(z) = \frac{1}{1 + e^{-z}} = \frac{1}{1 + e^{-\vartheta^Tx}}
$$
\noindent
con $z = \vartheta_0 + \vartheta_1 x_1 + \dots + \vartheta_i x_i$. Questa funzione ha un'interpretazione probabilistica molto banale, opportuna per \textbf{adattare i modelli di regressione lineare su problemi di classificazione}\footnote{Non si può pretendere di usare un modello di regressione lineare su task di classificazione, ma è comunque possibile, tramite l'uso della sigmoide, sfruttarlo per task di classificazione binaria.}. Osserviamo che:

\begin{itemize}
	\item $1-\overline{\sigma} = \sigma(z)$
	\item $\displaystyle\frac{\partial \overline{\sigma}(z)}{\partial t} =\overline{\sigma}(z)(1-\overline{\sigma}(z)) = \overline{\sigma}(z)\overline{\sigma}(-z)$
	\item È inoltre dimostrabile che $\displaystyle\overline{\sigma} = \frac{1}{2} + \frac{1}{2}\tanh\left(\frac{z}{2}\right)$. Questo ci apre le porte a implementazioni molto più semplici.
\end{itemize}

Concludiamo che la regressione logicistica, è ottimale per trovare opportuni parametri di $\vartheta^T$, che moltiplicati a $x$, ci permetteranno di stabilire il \textbf{decision boundary}, nella ben nota forma:

$$
\vartheta_0x_0 + \vartheta_1x_1 + \vartheta_2x_2 + \dots \vartheta_dx_d  
$$

\subsection{Vantaggi relativi all'uso della sigmoide}

\begin{itemize}
	\item Interpretazione probabilistica semplice. Da valori $\in[0,1]$.
	\item Derivabile, più liscia rispetto ad una step function.
	\item Introduce non lineareità, migliorando la classificazione.
\end{itemize}

\subsection{Funzione di Loss}
Avere una funzione di Loss associata al modello è fondamentale per capire come effettuare il training, e quali sono i migliori parametri di $\vartheta^T$ per la classificazione. 
Per modellare questa funzione (da minimizzare secondo l'algoritmo di discesa del gradiente), utilizzeremo due funzioni logaritmiche. La funzione di Loss sarà definita in funzione dell'etichetta $\hat{y}$.
$$
\text{Loss}(h_\vartheta(x), y) = \begin{cases}
	- \log (h_\vartheta(x)) \qquad\qquad\text{se } \hat{y} = 1\\
	- \log (1-h_\vartheta(x)) \qquad\text{ se } \hat{y} = 0\\
\end{cases}
$$

Questo, perché l'errore deve essere 1 quando $\hat{y} = 0$ e $y = 1$, o quando $\hat{y} = 1$ e $y = 0$.

\begin{center}
	\textit{Ai fini della semplicità e univocità della spiegazione, useremo $y$ per indicare ciò che fino ad ora abbiamo indicato con $\hat{y}$.}
\end{center}


\begin{figure}[tbph]
	\centering
	\includegraphics[width=0.75\linewidth]{images/loss-logistic-regression}
\end{figure}
\noindent
Possiamo esprimere la funzione di Loss anche in questo modo, rendendo unica la definizione della funzione.
$$
\text{Loss}(h_\vartheta(x), y) = -[y\log (h_\vartheta(x)) + (1-y)\log (1 - h_\vartheta(x))]
$$
\noindent
Definita la funzione di Loss, andremo a definire la funzione di costo

$$
J(\vartheta) = - \frac{1}{m} \sum_{i=1}^{m}(y^{(i)}\log (h_\vartheta(x)) + (1-y^{(i)})\log (1 - h_\vartheta(x)))
$$

\noindent
su cui sarà possibile applicare l'algoritmo di discesa del gradiente, fino alla convergenza del modello.
$$
\vartheta_j^{\text{new}} = \vartheta_j^{\text{old}} -\alpha\frac{\partial J(\vartheta)}{\partial \vartheta_j} \qquad \forall j
$$

\subsection{Derivata parziale della funzione di costo}

Necessaria per applicare la discesa del gradiente.
$$
\frac{\partial J(\vartheta)}{\partial \vartheta_j} = \frac{1}{m} \sum_{i=1}^{m} (\underbrace{h_\vartheta(x^{(i)})}_{(*)}- y^{(i)}))x_j^{(i)}) \qquad \forall j = 0, \dots, d
$$
(*) Questo membro nascone la funzione sigmoide $\overline{\sigma}(\vartheta^TX^{(i)})$

\subsection{Binary Cross Entropy Loss}

Su questo modello, diamo un'interpretazione probabilistica tramite il concetto di \textbf{entropia} e \textbf{Binary Cross Entropy Loss}.

$$
H(X) = -\sum_{k=1}^{K} p_k\log(p_k)
$$

con $p_k$ probabilità di essere di classe $k$.  La distribuzione di probabilità (e quindi l'entropia). Queste distribuzioni informazioni su:
\begin{itemize}
	\item Incertezza.
	\item Misura del disordine dalle classi.
	\item Quanto la probabilità è concentrata su una classe.
	\item Informazione (la distribuzione è molto informativa se è capace di distinguere in maniera opportuna).
\end{itemize}
Un esempio su $k=2$ è la funzione 
$$
H(X) = - p_2\log(p_2) - p_2\log(p_2)
$$
\begin{figure}[tbph]
	\centering
	\includegraphics[width=1\linewidth]{images/cross_entropy}
\end{figure}

\subsection{Overfitting nella classificazione}
Rischiamo di cadere in overfitting nell'utilizzo di classificatori polinomiali. Basterà usare i termini di regolarizzazione, ossia
$$
J(\vartheta) = - \frac{1}{m} \sum_{i=1}^{m}(y^{(i)}\log (h_\vartheta(x)) + (1-y^{(i)})\log (1 - h_\vartheta(x))) + \lambda\sum_{j=1}^n\vartheta_j^2
$$ 
\newpage

\section{Classificazione multiclasse e one vs all}  
Il dataset di input non avrà più etichette binarie, ma $k$ etichette. A ogni classe si associa un numero. Possiamo ottenere una classificazione multiclasse usando la metodologia \textbf{one vs all}. Avremo $k$ classificatori. Immaginiamo di avere un sistema di classificazione triangoli, quadrati e cerchi.
Avremo bisogno di tre classificatori, $h_{\vartheta_1}, h_{\vartheta_2}, h_{\vartheta_3}$, capaci di misurare $P(\text{triangoli}|x), P(\text{quadrato}|x), $ $P(\text{cerchio}|x)$. Prenderemo poi 

$$
\text{arg}\max_k h_{\vartheta_k}(\overline{x})
$$

\subsection{One vs one}
In questo caso, i classificatori distinguono classi a due a due. Si fanno poi le opportune valutazioni per capire se è possibile assegnare una classe, quale o se rejectare.

$$
\text{Numero di classificatori one vs one} = \frac{k(k-1)}{2}
$$
