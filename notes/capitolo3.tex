\chapter{Regressione}
Definiamo il compito di regressione in termini di come un algoritmo elabora un esempio
di input e produce un valore (o vettore) reale di output. Formalmente, vogliamo
apprendere una funzione
\[
h_\theta:\ \mathbb{R}^{d_1}\rightarrow \mathbb{R}^{d_2},\qquad d_1\ge 1,\ d_2\ge 1,
\]
a partire da un dataset supervisionato
\[
D=\{(x^{(i)},y^{(i)})\}_{i=1}^m,\qquad x^{(i)}\in\mathbb{R}^{d_1},\ y^{(i)}\in\mathbb{R}^{d_2}.
\]

\section{Ingredienti del task}
\begin{itemize}
  \item \textbf{Task}: predire valori reali a partire da input reali.
  \item \textbf{Modello}: ipotesi parametrica \(h_\theta\) che mappa input in output.
  \item \textbf{Dati}: coppie etichettate \((x^{(i)},y^{(i)})\).
  \item \textbf{Algoritmo di learning}: metodo per stimare \(\theta\) (ottimizzazione).
  \item \textbf{Funzione di loss}: misura lo scarto tra predizioni e target.
  \item \textbf{Valutazione}: metriche su validation/test per giudicare il modello.
\end{itemize}

\subsection{Tipi di regressione}
\begin{itemize}
  \item \textbf{Semplice (univariata)}: \(h_\theta:\mathbb{R}\to\mathbb{R}\) (\(d_1=d_2=1\)).
  \item \textbf{Multipla}: \(h_\theta:\mathbb{R}^{d_1}\to\mathbb{R}\) con \(d_1>1\).
  \item \textbf{Multivariata}: \(h_\theta:\mathbb{R}^{d_1}\to\mathbb{R}^{d_2}\) con \(d_2>1\) (più uscite).
\end{itemize}

\section{Regressione lineare semplice}
Nel caso \(d_1=d_2=1\) modelliamo la relazione tra un singolo ingresso \(x\in\mathbb{R}\) e
un'uscita reale \(y\in\mathbb{R}\) con una retta:
\[
h_\theta(x)=\theta_0+\theta_1\,x,
\]
dove \(\theta_0\) è l'intercetta e \(\theta_1\) la pendenza. ``Imparare'' significa scegliere
\(\theta=(\theta_0,\theta_1)\) in modo che le predizioni siano vicine ai corrispondenti target.

\subsection{Funzione di loss}
Misuriamo la qualità della retta con l'errore medio quadratico (MSE):
\[
J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\big(h_\theta(x^{(i)})-y^{(i)}\big)^2.
\]
Il fattore \(1/2\) è una costante di comodo che semplifica le derivate; il quadrato rende
positivi tutti i contributi ed enfatizza gli errori grandi. In regressione lineare \(J\) è
convessa rispetto ai parametri, quindi il minimo è unico (se c'è variabilità negli \(x^{(i)}\)).

\section{Regressione lineare multipla}
Estendiamo al caso con più variabili in ingresso. Dato il vettore
\(x=(x_1,\dots,x_n)\), usiamo un parametro per ogni dimensione più il bias:
\[
f(x)=\theta_0+\theta_1x_1+\theta_2x_2+\cdots+\theta_n x_n .
\]
Per semplicità poniamo \(x_0=1\) e definiamo il vettore esteso
\(
x=(x_0,x_1,\dots,x_n)^\top
\);
allora
\[
f(x)=\sum_{i=0}^n \theta_i x_i \;=\; \boldsymbol{\theta}^\top x.
\]
Questo modello è, in sostanza, un \emph{percettrone senza soglia}: la combinazione lineare
\(\boldsymbol{\theta}^\top x\) è l'uscita continua del regressore.

\section{Feature scaling}
Per far funzionare bene (e in fretta) la discesa del gradiente, le feature vanno portate
su scale simili. Due opzioni comuni:
\[
\text{z-scoring:}\quad x_j\leftarrow\frac{x_j-\mu_j}{\sigma_j},
\qquad
\text{min--max:}\quad x_j\leftarrow\frac{x_j-x_j^{\min}}{x_j^{\max}-x_j^{\min}}.
\]
Le statistiche \((\mu_j,\sigma_j,x_j^{\min},x_j^{\max})\) si calcolano solo sul training e
si riusano (senza ricalcolarle) su validation/test, per evitare data leakage.

\section{Algoritmo di discesa del gradiente}
L’obiettivo è scegliere \(\theta\) che minimizza \(J(\theta)\). La \emph{discesa del gradiente}
è un metodo iterativo che aggiorna i parametri nella direzione di massima diminuzione di \(J\).

\subsection{Versione batch per la regressione lineare}
Sia \(X\in\mathbb{R}^{m\times(n+1)}\) la design matrix con prima colonna di \(1\),
\(y\in\mathbb{R}^{m}\) il vettore dei target e \(\hat y=X\theta\) le predizioni. La loss è
\[
J(\theta)=\frac{1}{2m}\|X\theta-y\|_2^2,\qquad
\nabla_\theta J(\theta)=\frac{1}{m}X^\top(X\theta-y).
\]
\paragraph{Pseudocodice.}
\begin{enumerate}
  \item \textbf{Inizializza} in modo casuale: \(\theta^{(0)}=(\theta_0,\ldots,\theta_n)^\top\).
  \item \textbf{Calcola le derivate parziali}:
  \[
  \frac{\partial J(\theta)}{\partial \theta_j}
  =\frac{1}{m}\sum_{i=1}^m\big(\theta^\top \tilde x^{(i)}-y^{(i)}\big)\,\tilde x^{(i)}_j,\qquad j=0,\ldots,n,
  \]
  dove \(\tilde x^{(i)}=(1,x^{(i)}_1,\ldots,x^{(i)}_n)^\top\).
  \item \textbf{Aggiorna} i parametri (passo di ampiezza \(\alpha>0\)):
  \[
  \theta_j \leftarrow \theta_j - \alpha\,\frac{\partial J(\theta)}{\partial \theta_j},
  \qquad j=0,\ldots,n.
  \]
  \item \textbf{Ripeti} i passi 2–3 finché non è soddisfatto un criterio d’arresto
  (iterazioni massime, \(\|\nabla J(\theta)\|\) sotto soglia, variazione di \(J\) piccola).
\end{enumerate}
In forma compatta: \(\;\theta \leftarrow \theta - \frac{\alpha}{m}X^\top(X\theta-y)\).

\paragraph{Equazioni normali (soluzione chiusa).}
Se \(X^\top X\) è invertibile, il minimo di \(J\) è
\[
\theta^\star=(X^\top X)^{-1}X^\top y.
\]
Utile per problemi piccoli; per \(n\) o \(m\) grandi conviene la discesa del gradiente.

\section{Regressione polinomiale e feature mapping}
Se la relazione input–output è non lineare, usiamo un mapping
\(\phi:\mathbb{R}^{n}\to\mathbb{R}^{p}\) (poteri e interazioni) e poi una regressione
\emph{lineare nei parametri} nello spazio trasformato:
\[
h_\theta(x)=\theta^\top \phi(x).
\]
Esempio (grado \(2\), due feature):
\[
\phi(x_1,x_2)=\big(1,\ x_1,\ x_2,\ x_1^2,\ x_2^2,\ x_1x_2\big).
\]
Gradi più alti aumentano la capacità (meno underfitting) ma anche il rischio di overfitting
e i costi: il numero di termini cresce rapidamente con \(n\) e con il grado.

\section{Regolarizzazione}
Per ridurre l’overfitting penalizziamo pesi grandi. In \textbf{Ridge} (L2) la loss è
\[
J_\lambda(\theta)=\frac{1}{2m}\|X\theta-y\|_2^2+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2,
\]
dove tipicamente \(\theta_0\) non si penalizza. Aggiornamenti:
\[
\theta_0\leftarrow \theta_0-\alpha\,\frac{1}{m}\sum_{i=1}^m(\hat y^{(i)}-y^{(i)}),\qquad
\theta_j\leftarrow \theta_j-\alpha\left[\frac{1}{m}\sum_{i=1}^m(\hat y^{(i)}-y^{(i)})\tilde x^{(i)}_j+\frac{\lambda}{m}\theta_j\right]\ (j\ge 1).
\]

\section{Regressione multivariata}
Se \(d_2>1\), stimiamo più uscite in parallelo. Con \(Y\in\mathbb{R}^{m\times d_2}\) (righe \(y^{(i)\top}\))
e \(\Theta\in\mathbb{R}^{(n+1)\times d_2}\), il modello è \(\hat{Y}=X\Theta\). L’MSE matriciale è
\(J(\Theta)=\tfrac{1}{2m}\|X\Theta-Y\|_F^2\). Le colonne di \(\Theta\) (una per uscita) si
ottimizzano in modo indipendente; la soluzione chiusa generalizza a
\[
\Theta^\star=(X^\top X+\lambda \tilde M)^{-1}X^\top Y\qquad\text{(con Ridge opzionale)}.
\]

\section{Valutazione}
Metriche tipiche:
\[
\text{MSE}=\frac{1}{m}\sum_{i=1}^m\!\big(\hat y^{(i)}-y^{(i)}\big)^2,\quad
\text{RMSE}=\sqrt{\text{MSE}},\quad
\text{MAE}=\frac{1}{m}\sum_{i=1}^m\!\lvert \hat y^{(i)}-y^{(i)}\rvert.
\]
\noindent
\textbf{\(R^2\)} (coefficiente di determinazione):
\[
R^2=1-\frac{\sum_i\big(y^{(i)}-\hat{y}^{(i)}\big)^2}{\sum_i\big(y^{(i)}-\bar{y}\big)^2}.
\]
\textbf{REC curve}: ordinando gli errori assoluti \(e_i=\lvert \hat y^{(i)}-y^{(i)}\rvert\) e
tracciando, al variare di \(\varepsilon\), la frazione cumulativa di esempi con errore
\(\le\varepsilon\), si ottiene una curva di facilissima lettura; un’AUC maggiore indica in
genere prestazioni migliori.